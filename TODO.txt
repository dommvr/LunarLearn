ML:
    # Linear / logistic regression
    # Regularized linear models
    Perceptron / Linear SVM
    Naive Bayes
    KNN
    Decision trees
    Random forests
    Simple GBT
    KMeans
    PCA
    Matrix factorization
    Basic utilities (scaler, train/test split)

    -add metrics to ml/base.py
    -If you later add label remapping (classes not 0..Kâˆ’1), predict_proba stays the same, and you only need to map indices back to original labels in predict
    -add markov chain and HiddenMarkovModel (forward-backward, viterbi, em (baum-welch)) to probabilistic/stochastic
    -add ensure_tensor to model funcs
    -check add.at/scatter_add (recommender/utils)
    -add preprocessing/features/LabelEncoder to ml models that use it (instead of utils/_encode_labels)
    -implement model_search/split to general dataloaders and datasets
    -preprocessing and model_selecting maybe should be moved from ml folder
DL:
    -add helper func to tokenizer that creates regex patter based on true/false flags
    -check if freez params need requires_grad=False or just skip in optim
    -crop2d, cnnlstm1/2/3d, bidirectional
    -correct init_weights in cells
    -add freezemanager to trainer
    -input level normalization to dataloaders (per chanell mean/std)
    -skip_grad for tensors
    -compute hooks
    -zero_grad() optimization to dont pass zero grads
    -gradientchecker
    -save/load model
    -ops.expand_dims
    -bias on/off during layers init
    -spectralnorm layer
    -add metrics to trainer, bar, callbacks
    -inception_score
    -add dilation to other im2col/col2im if needed
    -dropconnect
    -add init to loss
    -change epsilon to eps
    -conv1d/2d/3d
    -change inception blocks to match inceptionv1

    spectralnorm (stop_grad)

    if a.skip_grad:
        a.grad = out.grad


-finish ml segment
-finish split set funcs
-finish quantization
-add save/load