ML:
    # Linear / logistic regression
    # Regularized linear models
    Perceptron / Linear SVM
    Naive Bayes
    KNN
    Decision trees
    Random forests
    Simple GBT
    KMeans
    PCA
    Matrix factorization
    Basic utilities (scaler, train/test split)

    -add metrics to ml/base.py
    -If you later add label remapping (classes not 0..K−1), predict_proba stays the same, and you only need to map indices back to original labels in predict
    -add markov chain and HiddenMarkovModel (forward-backward, viterbi, em (baum-welch)) to probabilistic/stochastic
    -add ensure_tensor to model funcs
    -check add.at/scatter_add (recommender/utils)
    -add preprocessing/features/LabelEncoder to ml models that use it (instead of utils/_encode_labels)
    -implement model_search/split to general dataloaders and datasets
    -preprocessing and model_selecting maybe should be moved from ml folder
DL:
    -change dataset to_tensor=False as default
    -add helper func to tokenizer that creates regex patter based on true/false flags
    -check if freez params need requires_grad=False or just skip in optim
    -crop2d, cnnlstm1/2/3d, bidirectional
    -correct init_weights in cells
    -add freezemanager to trainer
    -input level normalization to dataloaders (per chanell mean/std)
    -skip_grad for tensors
    -compute hooks
    -zero_grad() optimization to dont pass zero grads
    -gradientchecker
    -save/load model
    -ops.expand_dims
    -bias on/off during layers init
    -spectralnorm layer
    -add metrics to trainer, bar, callbacks
    -inception_score
    -add dilation to other im2col/col2im if needed
    -dropconnect
    -add init to loss
    -change epsilon to eps
    -conv1d/2d/3d
    -change inception blocks to match inceptionv1

    spectralnorm (stop_grad)

    if a.skip_grad:
        a.grad = out.grad


Datasets:
    ML:
        -Iris (m class)
        -Wine (m class)
        -Breast Cancer Wisconsin (b class)
        -Digits 8x8 (m class)
        -Titanic (b class)
        -Adult/Census Income (b class)
        -California Housing (regression)
        -Diabetes (regression)
        -Ames Housing (regression)
        -20 Newsgroup (text m class)
        -SMS Spam (b class)
        -IMDb Reviews (sentiment (binary))
        -MNIST (m class)
        -Fashion MNIST (m class)
        -Olivetti Faces (unsupervised/semi-supervised/class)
        -MovieLens 100k/1M (MatrixFactorization/BiasedMF)
        -GoodBooks-10k

    
    DL:
        -ImageNet-1k/Tiny
        -CIFAR-10/100
        -STL-10
        -Pascal VOC 2007 + 2012
        -COCO 2017
        -WIDER FACE 
        -CrowdHuman
        -OpenImages 
        -Pascal VOC Segmentation
        -Cityscapes
        -ADE20K
        -COCO-Stuff
        -CamVid
        -CelebA/CelebA-HQ
        -LSUN Bedrooms/churches/towers
        -FFHQ
        -WikiText-2/WikiText-103
        -OpenWebText
        -BookCorpus
        -C4
        -text finetuning (one generic TextClassificationDataset with task-specific configs is enough)
            -GLUE
            -SQuAD v1.1/v2
            -CoNLL-2003
            -XNLI/MultiNLI
        -COCO CAptions
        -Flickr30k
        -Conceptual CAptions
        -LAION
        -Moving MNIST
        -UCF101
        -Kinetics-400
        -Something-Something v2

Vision: detection / instance seg / tracking

Pascal VOC (07/12 unified)
COCO 2017
WIDER FACE
CrowdHuman
MOT17 (tracking)

Vision: semantic segmentation

Cityscapes
ADE20K
COCO-Stuff
CamVid (optional if you want a “small Cityscapes-like”)
Generative / faces
CelebA (attributes)
FFHQ (high-quality faces)
LSUN (Bedrooms/Churches as classic unconditional gen)

NLP: LM + finetuning benchmarks
WikiText-103 (keep WikiText-2 as a tiny debug variant)
OpenWebText or C4 (pick one as “large LM text”; make the other optional)
GLUE (covers a bunch of standard classification-style tasks)
SQuAD (QA)
CoNLL-2003 (NER)
XNLI (cross-lingual)
Multimodal (if you want it in-core; otherwise make it optional)

Swap in 1–2 of these by removing the least-used above:
COCO Captions


-keep only realisticly usable datasets
-finish ml segment
-finish split set funcs
-finish quantization
-add save/load


VOC2007 detection
Oxford-IIIT Pet
AG News
tiny shekespear


dataset:
    -remove dtype
    -change xp -> np in load_*
    -(class) change DTYPE